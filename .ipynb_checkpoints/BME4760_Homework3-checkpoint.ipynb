{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Part a\n",
    "a) Load the dataset in an iPython notebook \\[2 point\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: *Use the accompanied dataset for this homework. Read the dataset description below carefully and make sure you understand the dataset features and values. \n",
    "Dataset description: This dataset (Colon Cancer) contains expression levels of 2000 genes taken in 62 different samples. For each sample, it is indicated whether it came from a tumor biopsy or not (0/1). Note that the first column in the file corresponds to the label of the instance. See the Genes.txt file for description of genes and tissues.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw_data = pd.read_csv('HW3data.csv', header=None)\n",
    "raw_table = pd.read_table('Genes.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = raw_table.loc[:, 0]\n",
    "temp = pd.DataFrame(['value'])\n",
    "header = pd.concat([temp, header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    (value,)  (Hsa.3004,)  (Hsa.13491,)  (Hsa.13491,)  (Hsa.37254,)  \\\n",
      "0          0     2.080754      1.099069      0.927763      1.029081   \n",
      "1          1     1.109457      0.786453      0.445560     -0.146323   \n",
      "2          0    -0.676530      1.693100      1.559247      1.559983   \n",
      "3          1     0.534396      1.677537      1.489030      0.778605   \n",
      "4          0    -1.018903      0.511080      0.755641      1.013816   \n",
      "5          1    -1.185369     -0.514473     -0.566634      1.224720   \n",
      "6          0     1.779054      0.423947      0.820696      2.525687   \n",
      "7          1    -0.889638     -0.315453     -0.073131      1.157503   \n",
      "8          0    -0.659694     -0.184388     -0.540022      1.122418   \n",
      "9          1    -1.225801     -0.212615     -0.588923      1.335412   \n",
      "10         0    -0.377282     -2.620493     -2.763910      0.612038   \n",
      "11         1     1.639214      0.663551      0.324924      1.456457   \n",
      "12         0     0.125390      1.286657      1.505225      0.804243   \n",
      "13         1     0.055593      0.758397      0.857047      0.159382   \n",
      "14         0    -0.861022      0.432429      0.404421     -0.230533   \n",
      "15         1    -0.672304     -0.484720     -0.667529     -0.703183   \n",
      "16         0     1.605147     -0.771553     -0.819771      0.292317   \n",
      "17         1     0.867577      0.501470      0.242006      0.417230   \n",
      "18         0     0.590751      0.440645      0.585110      1.470657   \n",
      "19         1    -0.311476     -1.482608     -1.697240      1.728988   \n",
      "20         0     0.369171      0.742324      0.584255      0.617444   \n",
      "21         1     0.137575      0.801932      0.673334      0.089943   \n",
      "22         0    -1.163365     -1.214555     -1.359716     -1.237726   \n",
      "23         1     0.907830      1.640852      1.416463      0.953309   \n",
      "24         0     0.261661     -0.126443      0.084908     -0.461416   \n",
      "25         0     1.070146      0.393399      0.695527      0.180488   \n",
      "26         0     1.440709      0.649996      0.873454      0.190425   \n",
      "27         0     0.603603      1.226511      1.338774      0.105289   \n",
      "28         0     0.668765      0.444708      0.397101      0.643610   \n",
      "29         0     1.196460      0.259518      0.023820      0.661112   \n",
      "..       ...          ...           ...           ...           ...   \n",
      "32         0     0.704230     -1.266950     -1.082385      0.282644   \n",
      "33         0     0.451197      1.533083      1.493214      0.108655   \n",
      "34         0     0.173573     -0.086988      0.049312      0.154649   \n",
      "35         0    -0.552768     -0.394988     -0.067447     -1.468454   \n",
      "36         0    -1.633654      1.224956      1.036479      1.108610   \n",
      "37         0    -1.154575     -1.139515     -0.852773     -1.805587   \n",
      "38         1    -1.765218      0.434114      0.397484     -2.180245   \n",
      "39         0     1.483438      0.567198      0.573307     -0.202935   \n",
      "40         0    -0.953049      1.107939      1.328478     -1.644577   \n",
      "41         1     0.214162      0.512283      0.318795      0.375563   \n",
      "42         1     0.426636     -1.864192     -1.847756     -0.258318   \n",
      "43         0     0.781703     -2.166325     -1.935412     -0.591776   \n",
      "44         0    -0.333621     -0.331659     -0.039726     -0.684055   \n",
      "45         0     0.798422     -2.030147     -1.800778     -0.435794   \n",
      "46         0    -2.345574     -1.266346     -1.295295     -1.866567   \n",
      "47         1    -0.793556     -0.764538     -0.615078     -1.524149   \n",
      "48         0     1.016578      0.165638     -0.216089     -0.323165   \n",
      "49         1    -0.810990     -0.344152     -0.396643     -0.912228   \n",
      "50         1    -0.082485     -0.068667      0.054522     -0.487776   \n",
      "51         0    -0.215307     -0.078671      0.099442     -1.576599   \n",
      "52         0     0.177628      0.549644      1.016878     -1.188864   \n",
      "53         1    -1.819608      0.087764      0.334434     -0.566902   \n",
      "54         1    -0.149788     -0.537464     -0.865811     -0.439747   \n",
      "55         0    -0.642749     -0.646193     -0.924490     -0.390230   \n",
      "56         0    -2.129373      0.025128      0.007812     -0.510764   \n",
      "57         0     0.488711      0.764970      0.920233     -0.958693   \n",
      "58         0    -0.146703      0.112155      0.282926     -1.135509   \n",
      "59         1     0.200706     -0.668545     -0.935933     -0.886087   \n",
      "60         0     0.829749      0.299447      0.130738      0.335530   \n",
      "61         1     0.566684     -0.533660     -0.761951     -0.087032   \n",
      "\n",
      "    (Hsa.541,)  (Hsa.20836,)  (Hsa.1977,)  (Hsa.44472,)  (Hsa.3087,)  \\\n",
      "0    -0.130763      1.265460    -0.436286      0.728881     2.107979   \n",
      "1    -0.996316      0.555759     0.290734     -0.145259     1.132660   \n",
      "2    -0.982179     -1.358507    -1.313994     -0.455067     0.295214   \n",
      "3    -0.183776     -1.116850    -1.487557     -0.579511     0.292683   \n",
      "4     0.529899      0.160440    -0.087055      1.295290     0.458736   \n",
      "5     0.619244     -0.684713    -0.798129      1.368770    -0.697007   \n",
      "6     0.666921      0.661346     0.425365      0.165247     1.967905   \n",
      "7    -0.311039     -0.364472    -1.621636      1.192999     0.689805   \n",
      "8     0.562609     -2.988315    -2.349808     -1.325007    -0.017002   \n",
      "9    -0.356505      0.354394     0.699607      0.190782    -0.139117   \n",
      "10   -0.155718     -1.456066     0.683292     -1.031567     0.718861   \n",
      "11   -0.170587     -0.443486    -0.832590     -0.928334     1.320070   \n",
      "12    1.384430      0.633277     1.682128      1.924996     0.072503   \n",
      "13    1.020294      0.733855     1.141088      1.213815    -0.236974   \n",
      "14    0.492867      0.274014    -0.873134      0.609713    -0.112962   \n",
      "15    1.872858      1.295695     1.044664     -1.255296    -0.686953   \n",
      "16    1.648191      0.192798     1.348876      1.284650     1.989654   \n",
      "17    1.723881     -1.249272    -0.815193      2.015221     1.160137   \n",
      "18    0.724532     -1.874136    -2.038916      1.115607     1.225129   \n",
      "19    0.511898     -0.943735    -0.285187      1.028791    -0.365555   \n",
      "20   -1.513952      1.180225    -0.268009      0.513435     0.428941   \n",
      "21   -1.572563      0.878675     0.506696      0.222351     1.146443   \n",
      "22    1.509944      0.462035     0.989522      1.017890    -1.057706   \n",
      "23    2.895000      0.322749     1.517181      2.689922     0.509099   \n",
      "24    0.420518      0.386768     0.257387      1.184280    -0.059124   \n",
      "25   -0.539207      0.520514     1.279115     -0.856697     0.544119   \n",
      "26   -0.368266      1.162666     1.748127     -0.859296     1.142555   \n",
      "27    0.012994      0.735462     1.281292      0.208414     0.605721   \n",
      "28   -1.578104      0.852593     1.579514     -1.791649     0.432917   \n",
      "29   -0.757198      0.931691     0.942438     -1.034322     1.033307   \n",
      "..         ...           ...          ...           ...          ...   \n",
      "32    0.599121      1.176305     0.821073      0.267318     0.377003   \n",
      "33    0.118696      0.359560    -0.080691      1.088030     0.041763   \n",
      "34   -0.854644      0.395668    -0.501723     -0.606768     0.427740   \n",
      "35    0.986678     -0.950956    -0.564847      0.906280    -0.336318   \n",
      "36   -2.121205      0.087452     0.285415     -0.453603     0.292197   \n",
      "37    1.211636     -0.043248     1.020932      0.475199    -0.733753   \n",
      "38   -0.482221      0.579913     0.007180     -0.396361    -2.186182   \n",
      "39    1.108224      1.627166     1.202437     -0.093951     0.779752   \n",
      "40   -0.074236     -0.776688    -1.405831     -0.338663    -0.583577   \n",
      "41   -0.319845     -1.907147    -1.601023      0.697753    -0.008599   \n",
      "42   -1.380025     -0.065725    -0.268582     -0.769468    -2.508847   \n",
      "43   -0.140932     -1.005584    -0.891690     -0.254486     0.518198   \n",
      "44   -1.182427      1.274619     0.962359     -1.101843    -0.192507   \n",
      "45    0.044236     -1.160167    -0.552252      0.297195    -0.647570   \n",
      "46   -0.665226     -0.325585    -0.164589     -0.191533    -1.855450   \n",
      "47   -1.693305     -1.622770    -0.292296     -0.927984    -1.256091   \n",
      "48   -1.256994      0.634088     0.721427     -1.759378     0.474816   \n",
      "49    0.301997      0.567269     0.458596     -0.449325    -0.141738   \n",
      "50    0.311532      1.165237     0.297936     -0.143873    -0.156585   \n",
      "51    1.214732     -0.403080    -0.901705      0.446720    -0.046425   \n",
      "52    0.908239      0.043510    -1.113660      0.489169    -0.061382   \n",
      "53    0.127363     -0.683805    -1.144701      0.270141    -1.706886   \n",
      "54   -1.324960     -1.683660    -0.189472     -0.767448    -0.406531   \n",
      "55   -0.193051     -0.457995    -0.024138     -0.516478    -2.929511   \n",
      "56   -0.418168     -1.437657    -1.760120     -0.905048    -1.363562   \n",
      "57   -0.147683      0.588944     0.097142     -0.212724    -0.827331   \n",
      "58    0.683854      1.449191     0.963985      0.394901    -0.543475   \n",
      "59   -1.372156      0.128890     0.488561     -2.447959    -0.445897   \n",
      "60   -0.401385      0.495544    -0.646200     -1.041644    -0.267708   \n",
      "61   -0.283129      0.832089    -0.330326     -0.583525    -0.258754   \n",
      "\n",
      "       ...       (Hsa.2618,)  (Hsa.27285,)  (Hsa.41260,)  (Hsa.14822,)  \\\n",
      "0      ...         -0.825403     -0.138451      0.382957      0.876697   \n",
      "1      ...         -1.056288     -0.205499     -1.815374      0.324373   \n",
      "2      ...          1.242968      1.230157     -2.038999      2.366093   \n",
      "3      ...          0.559852     -0.593149     -4.440577      1.720705   \n",
      "4      ...          0.227110      0.497628     -0.083921     -0.382733   \n",
      "5      ...          0.926855      0.302304      0.302785     -1.170087   \n",
      "6      ...          0.284194     -0.555516     -1.455897     -0.240853   \n",
      "7      ...         -0.113531     -0.485290     -0.094577     -0.809093   \n",
      "8      ...         -0.819396     -0.952811      0.065197      0.985648   \n",
      "9      ...          1.772469      0.804056     -0.361595     -0.975587   \n",
      "10     ...          0.115201      1.137555      0.306306     -1.807855   \n",
      "11     ...          0.881965     -0.772486      0.048502     -0.290692   \n",
      "12     ...          0.668764      0.795207     -0.141979     -0.328349   \n",
      "13     ...          0.425991      0.226252     -1.182270      0.945301   \n",
      "14     ...          0.922434     -0.586524      0.897438      0.538331   \n",
      "15     ...          1.053262     -0.570598      0.428686      0.517352   \n",
      "16     ...         -4.302872     -0.364189      1.121105     -0.628776   \n",
      "17     ...         -1.126207     -0.030568     -0.288405     -1.828125   \n",
      "18     ...         -0.525329     -0.934040      0.008399     -0.476887   \n",
      "19     ...          1.184450      0.515086     -0.388818     -2.137428   \n",
      "20     ...         -0.517142     -0.494955     -0.748101     -0.151951   \n",
      "21     ...         -0.306509      0.009629     -1.194875      0.492434   \n",
      "22     ...          0.365183      0.282023      1.659938     -1.356941   \n",
      "23     ...          0.951224      1.332461      0.269523     -2.526484   \n",
      "24     ...         -0.320691     -0.090327     -0.144941      0.917479   \n",
      "25     ...         -0.561481      1.508077      0.556502     -0.053134   \n",
      "26     ...          0.246977      1.430460      0.490623     -0.069066   \n",
      "27     ...         -1.044283      0.531571      0.045947      0.543013   \n",
      "28     ...         -0.375764      1.895205     -0.087835      0.779827   \n",
      "29     ...         -0.051668      0.675375      0.032776      0.177638   \n",
      "..     ...               ...           ...           ...           ...   \n",
      "32     ...          0.292064      0.478941      1.103350     -1.254981   \n",
      "33     ...         -0.909571      0.401607      0.124062      0.408449   \n",
      "34     ...         -1.181713     -0.374841     -0.158974     -0.380094   \n",
      "35     ...         -1.074213      0.442287      0.900869     -1.051292   \n",
      "36     ...          0.428210      1.913617     -1.500744      1.833650   \n",
      "37     ...         -1.735276      1.296925      1.524022     -0.917120   \n",
      "38     ...          0.686778      0.644273      0.479698      0.975548   \n",
      "39     ...         -0.525945      0.750996      0.935524     -0.132938   \n",
      "40     ...         -0.736461     -3.156028      0.569853      0.636454   \n",
      "41     ...         -0.016903     -0.256217      0.069957     -0.059088   \n",
      "42     ...          0.315847     -1.995580     -1.221399     -0.010682   \n",
      "43     ...         -0.941889      0.144534     -0.096478     -0.452878   \n",
      "44     ...          1.483875      0.481589     -0.187037      0.417466   \n",
      "45     ...         -0.809573      0.062506      0.593717     -0.809891   \n",
      "46     ...         -1.267359     -0.837099      0.349589     -0.664065   \n",
      "47     ...          1.713019      1.207519     -0.935843     -0.063432   \n",
      "48     ...          0.049964      0.071878     -0.445551      0.427269   \n",
      "49     ...          0.617989      0.098371      0.649645      0.846294   \n",
      "50     ...          1.510051     -1.349517     -0.659209     -0.745793   \n",
      "51     ...         -0.525371     -0.379801      1.236858     -0.521071   \n",
      "52     ...         -0.653858     -1.370089      1.474176      0.456790   \n",
      "53     ...          0.509312     -0.430256      0.072601      0.638787   \n",
      "54     ...         -0.064966      0.413162     -0.195991      0.312849   \n",
      "55     ...          0.212534      0.424437     -0.027541      0.501833   \n",
      "56     ...          1.481529     -1.041608      1.329088      2.126108   \n",
      "57     ...         -0.319253     -2.880039      0.322515      1.150149   \n",
      "58     ...         -0.544976     -1.315633      0.404797     -0.364126   \n",
      "59     ...          0.846102      0.514963     -1.398877      0.771972   \n",
      "60     ...          0.843415      0.436470      0.082887     -0.121180   \n",
      "61     ...          0.151594     -0.540061      0.915846      1.025732   \n",
      "\n",
      "    (Hsa.336,)  (Hsa.984,)  (Hsa.35124,)  (Hsa.3952,)  (Hsa.32734,)  \\\n",
      "0    -0.216234   -1.408300      0.393327    -0.148522      1.591533   \n",
      "1    -1.296909   -0.870757      1.108739     1.094010     -0.492141   \n",
      "2     0.820656    1.404501      0.176860    -0.086285     -0.390878   \n",
      "3    -0.124617   -0.435880      0.228440    -0.893938      1.005879   \n",
      "4    -0.913389    1.122928      0.834571    -0.283786     -2.860340   \n",
      "5    -1.189162    0.418884     -2.247347    -0.455263     -1.528083   \n",
      "6     0.249138   -0.915572     -0.764530    -0.808293      0.003886   \n",
      "7     0.453226   -0.009268     -0.872640    -1.730826      0.665384   \n",
      "8     0.745522    0.508879      0.846929     0.644346      0.156497   \n",
      "9    -0.652528   -0.106173     -0.613650    -0.886065      0.645764   \n",
      "10    0.899761    0.750847      1.847261     1.500090      1.013120   \n",
      "11   -0.970130   -0.062976      1.019466     0.998675     -0.112029   \n",
      "12   -0.111059    0.443720     -1.034155    -1.383400     -0.958857   \n",
      "13   -0.297952   -1.460249     -0.177619    -1.151216      0.722640   \n",
      "14   -1.281134    0.539094     -0.343020    -0.269283      0.003406   \n",
      "15   -0.052869   -1.813498     -1.282465    -1.565887     -1.291665   \n",
      "16   -1.452871    1.065736      0.929366     0.850532      0.092422   \n",
      "17    0.378633   -0.861010      0.567541    -0.237284      1.509842   \n",
      "18   -1.086239    0.437081     -0.718286     0.206024     -2.804114   \n",
      "19   -0.067351    0.266181     -0.481120    -1.212296      0.778511   \n",
      "20   -0.330637   -1.791074      1.330228     0.145018      0.413500   \n",
      "21   -0.095780   -1.453297      0.351192     0.005632      1.104979   \n",
      "22   -0.905060    0.402223     -0.248060    -0.563791      0.396050   \n",
      "23   -3.164198   -0.381382     -0.340095    -2.461643     -0.937018   \n",
      "24   -1.117696   -3.595862     -0.160189     0.325858     -0.101886   \n",
      "25    0.866155   -0.904096     -0.246096     0.980219     -1.537980   \n",
      "26    0.458956   -0.929896      0.631799     0.350061     -1.761495   \n",
      "27    0.840315   -0.355442      0.196545     0.230857      0.709464   \n",
      "28    2.017198   -0.408198      0.239587     0.898247     -0.269794   \n",
      "29    1.646497   -0.684288      0.154495     1.474240      0.517323   \n",
      "..         ...         ...           ...          ...           ...   \n",
      "32    1.061866   -1.294651      1.048844    -0.254242      1.365350   \n",
      "33   -0.493232    0.925940     -0.922493    -0.144082     -0.839826   \n",
      "34   -0.336835   -0.181890      1.158283     0.455972      0.647447   \n",
      "35   -0.816867    0.148245      0.218910    -0.104252     -1.009324   \n",
      "36    2.854865   -0.437884      0.005739     0.008833     -0.252912   \n",
      "37   -0.044104   -0.425193      0.301845    -0.566719     -1.419485   \n",
      "38   -1.429519    0.173506     -1.959468    -2.870571     -0.833660   \n",
      "39    0.527780    0.292531      0.870360     1.056712     -0.318613   \n",
      "40   -1.537726    0.639513     -0.232347    -0.737874      0.808167   \n",
      "41    0.796956   -0.131166     -0.766188    -0.311352      0.335782   \n",
      "42    1.343143    0.735802      1.460692     1.276620      1.355918   \n",
      "43    1.222409    1.115541      1.856981     1.660051      0.620906   \n",
      "44    0.055298   -1.201560      0.622394     0.003722      1.009665   \n",
      "45    0.433926    0.079638      1.239839     1.148068     -0.024702   \n",
      "46   -0.684032    0.095660      0.941494    -0.649761     -0.640791   \n",
      "47   -0.138106    0.889653     -0.644733    -0.986025     -0.728026   \n",
      "48    0.003540   -0.084864      0.646203     1.266569      1.241043   \n",
      "49   -0.185618    1.041692     -0.641211    -0.301740     -0.311732   \n",
      "50    0.929339   -0.796802     -0.180983     0.370376      0.989733   \n",
      "51    0.354033   -0.250985     -0.470433     0.072394      1.035807   \n",
      "52   -1.054447    0.408274     -1.856790    -0.888702      0.519268   \n",
      "53   -0.419346   -0.109626     -1.700997    -1.697602     -0.191326   \n",
      "54    0.637454    1.503764      0.579904     1.632508     -0.723773   \n",
      "55    0.482323    0.604469     -0.861672     0.024896     -0.531409   \n",
      "56    0.011270    1.987943     -2.116854     0.712721      1.315854   \n",
      "57    1.132339    0.437734      0.174756     0.511431     -0.685264   \n",
      "58   -1.347496    0.075607     -2.387867     0.347011     -1.013400   \n",
      "59    0.203989   -0.214999      0.585247     0.605018      1.344914   \n",
      "60    0.407349    0.664057      0.533698     0.985630     -0.210661   \n",
      "61    0.786296    0.870661      0.154527    -0.453840      0.194535   \n",
      "\n",
      "    (Hsa.9683,)  \n",
      "0     -0.217481  \n",
      "1     -1.554079  \n",
      "2     -0.089465  \n",
      "3     -0.631247  \n",
      "4      0.280871  \n",
      "5      0.327891  \n",
      "6     -0.379341  \n",
      "7      0.977573  \n",
      "8     -0.147716  \n",
      "9      0.142760  \n",
      "10     0.067917  \n",
      "11    -0.224523  \n",
      "12    -0.020107  \n",
      "13    -0.044954  \n",
      "14     1.213104  \n",
      "15     1.190718  \n",
      "16     1.670912  \n",
      "17     2.055111  \n",
      "18     0.198566  \n",
      "19     0.688857  \n",
      "20    -0.629505  \n",
      "21     0.153397  \n",
      "22     2.362042  \n",
      "23     1.307743  \n",
      "24     0.515232  \n",
      "25    -0.623124  \n",
      "26    -0.670612  \n",
      "27    -0.798043  \n",
      "28    -0.593288  \n",
      "29    -1.032721  \n",
      "..          ...  \n",
      "32     0.153579  \n",
      "33    -1.210314  \n",
      "34     0.763341  \n",
      "35     1.331196  \n",
      "36    -2.614152  \n",
      "37     1.953458  \n",
      "38     0.192293  \n",
      "39    -0.063503  \n",
      "40    -1.221314  \n",
      "41    -0.412429  \n",
      "42     0.721191  \n",
      "43     0.302660  \n",
      "44    -0.235593  \n",
      "45     0.480412  \n",
      "46    -0.034518  \n",
      "47    -1.385885  \n",
      "48    -1.336079  \n",
      "49    -0.051559  \n",
      "50     0.067339  \n",
      "51     0.229729  \n",
      "52     0.008556  \n",
      "53     0.153198  \n",
      "54    -2.451679  \n",
      "55     0.408755  \n",
      "56     0.462371  \n",
      "57    -0.604012  \n",
      "58    -0.013589  \n",
      "59    -2.485066  \n",
      "60    -0.391249  \n",
      "61     0.064150  \n",
      "\n",
      "[62 rows x 2001 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_data.columns = header\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Part b\n",
    "b) Feature selection is an important machine-learning task that allows us to select the most important features in a given dataset. Scikit-learn provides multiple methods for choosing the best features. Use the Recursive Feature Elimination method (REF) with crossvalidation [here](http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py), and show a plot to demonstrate the performance versus number of selected features \\[11 points\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buidling a classification task\n",
    "X, Y = make_classification(n_samples=1000,\n",
    "                           n_features=62,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=2,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=8,\n",
    "                           n_clusters_per_class=1,\n",
    "                           random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an RFE object\n",
    "svc = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "   estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "   n_jobs=1, scoring='accuracy', step=1, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running accuracy scoring and cross validation\n",
    "rfecv = RFECV(estimator=svc,\n",
    "              step=1,\n",
    "              cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "\n",
    "# Fitting model\n",
    "rfecv.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting performance vs number of selected features\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23397242, 0.48272338, 0.8138493 , 0.81189723, 0.81190923,\n",
       "       0.7999328 , 0.79393258, 0.79588465, 0.77588393, 0.76690161,\n",
       "       0.76995572, 0.75091303, 0.73785856, 0.74182271, 0.73584649,\n",
       "       0.72075595, 0.70379734, 0.69881516, 0.68584469, 0.69480301,\n",
       "       0.67188019, 0.66583197, 0.66579597, 0.67080215, 0.65573561,\n",
       "       0.66480193, 0.66183183, 0.64979539, 0.6528495 , 0.638873  ,\n",
       "       0.62187839, 0.6278186 , 0.6138421 , 0.62184239, 0.60978195,\n",
       "       0.62083635, 0.60585381, 0.60582981, 0.59675148, 0.57987688,\n",
       "       0.58374501, 0.58380502, 0.57891884, 0.56590037, 0.57290662,\n",
       "       0.57191259, 0.57685877, 0.57182859, 0.58381702, 0.57993688,\n",
       "       0.57684677, 0.56586437, 0.56290626, 0.5639123 , 0.5748947 ,\n",
       "       0.56890648, 0.55990016, 0.56790044, 0.57188859, 0.56784044,\n",
       "       0.5748707 , 0.57288262])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part c\n",
    "c) Use the holdout method for testing using only the selected features. Report  the performance. \\[5 points\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\skyfr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup values and label\n",
    "X_value = raw_data.iloc[:, 1:2001].values # Values for gene expression\n",
    "y_value = raw_data.iloc[:, 0].values # Labels for gene markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test data\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_value,\n",
    "                     y_value,\n",
    "                     test_size=0.20,\n",
    "                     stratify=y_value,\n",
    "                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (49, 2000)\n",
      "Y_train shape:  (49,)\n",
      "X_test shape:  (13, 2000)\n",
      "Y_test shape:  (13,)\n"
     ]
    }
   ],
   "source": [
    "# Explore the dimensions of training and testing data.\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"Y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.66666667 0.66666667 0.8        0.8        0.8        0.8\n",
      " 1.         1.         1.         1.        ]\n",
      "CV accuracy: 0.853 +/- 0.129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# effective way to write cross-validation, jobs = number of CPU's you will run if available\n",
    "scores = cross_val_score(estimator=svc,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part d\n",
    "d) Create a GitHub repository and share your code via GitHub with the instructor by submitting the link on Canvas \\[2 points\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Github code here: https://github.com/mdelbasha/BME4760_HW3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
